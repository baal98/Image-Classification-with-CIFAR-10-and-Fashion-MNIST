{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, we'll preprocess the datasets to make them suitable for training our model. This includes normalization (scaling pixel values to the range [0,1]), one-hot encoding the labels, and any other necessary transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies\n",
    "\n",
    "[Back to Main](../Project.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "\n",
    "\n",
    "# Loading CIFAR-10 data\n",
    "(train_images_cifar, train_labels_cifar), (test_images_cifar, test_labels_cifar) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Loading Fashion MNIST data\n",
    "(train_images_fmnist, train_labels_fmnist), (test_images_fmnist, test_labels_fmnist) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10 Data Preparation\n",
    "\n",
    "For CIFAR-10, the data consists of color images. Here's what we'll do:\n",
    "\n",
    "1. **Normalization**: Neural networks generally perform better on data that's on a smaller scale. We'll scale the pixel values from [0,255] to [0,1].\n",
    "2. **One-hot Encoding Labels**: Instead of a singular value representing each class, we'll use one-hot encoding. This converts our integer labels into a binary matrix, which is more suitable for classification tasks in deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the pixel values for CIFAR-10\n",
    "train_images_cifar = train_images_cifar / 255.0\n",
    "test_images_cifar = test_images_cifar / 255.0\n",
    "\n",
    "# One-hot encoding the labels for CIFAR-10\n",
    "train_labels_cifar = tf.keras.utils.to_categorical(train_labels_cifar)\n",
    "test_labels_cifar = tf.keras.utils.to_categorical(test_labels_cifar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save files needed for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../saved_models/cifar_data.npz', train_images=train_images_cifar, test_images=test_images_cifar, \n",
    "         train_labels=train_labels_cifar, test_labels=test_labels_cifar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST Data Preparation\n",
    "\n",
    "The Fashion MNIST dataset contains grayscale images. The steps for preparation will be similar to CIFAR-10:\n",
    "\n",
    "1. **Normalization**: We'll scale the pixel values to the range [0,1].\n",
    "2. **One-hot Encoding Labels**: As with CIFAR-10, we'll convert the integer labels into a binary matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the pixel values for Fashion MNIST\n",
    "train_images_fmnist = train_images_fmnist / 255.0\n",
    "test_images_fmnist = test_images_fmnist / 255.0\n",
    "\n",
    "# One-hot encoding the labels for Fashion MNIST\n",
    "train_labels_fmnist = tf.keras.utils.to_categorical(train_labels_fmnist)\n",
    "test_labels_fmnist = tf.keras.utils.to_categorical(test_labels_fmnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save files needed for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('../saved_models/fmnist_data.npz', train_images=train_images_fmnist, test_images=test_images_fmnist, \n",
    "         train_labels=train_labels_fmnist, test_labels=test_labels_fmnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data now prepared, we're better positioned to build and train our machine learning models. Properly prepared data ensures that our models train efficiently and achieve higher accuracy. \n",
    "\n",
    "In the next section, we'll delve into model design, exploring architectures suitable for our image classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The cell below is commented out for performance reasons during regular runs. However, if you wish to save the trained models for testing or future use, you can uncomment and execute the cell. It's worth noting that the saved model files have been prepared in advance and are optimized for the testing scenarios presented in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train_images_cifar to an h5 file\n",
    "with h5py.File('../saved_models/train_images_cifar_enhanced.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"cifar_data\", data=train_images_cifar)\n",
    "\n",
    "# Save train_images_fmnist to an h5 file\n",
    "with h5py.File('../saved_models/train_images_fmnist_enhanced.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"fmnist_data\", data=train_images_fmnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Main](../Project.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
